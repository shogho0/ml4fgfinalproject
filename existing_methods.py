# -*- coding: utf-8 -*-
"""Existing Methods.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1vNknpCCSjQtpyiotPscenbNPDEaO3Qbw

# ML4FG Final Report: Modeling Colorectal Cancer Gene Expression Distributions using Mixture Models

Authors: Shomik Ghose (sg3789@columbia.edu), Austin Tao (alt2177@columbia.edu)
"""

#Import necessary packages
import pandas as pd
import numpy as np
import matplotlib as mpl
import matplotlib.pyplot as plt

from google.colab import drive
drive.mount('/content/drive')

"""# Data Reading and Preprocessing"""

#Importing dataset
df = pd.read_csv("drive/MyDrive/ML4FG Final Project/Bodmer_microarray_phenotype.csv",index_col=0)
df.head()

df.shape

"""The dataset contains 54,702 genes and 78 samples. The samples represent colorectal cancer cell lines.

Ex. The link to the C10 sample is here: https://www.cancertools.org/cell-lines/151755
"""

df.index.unique()

"""**Handling Duplicates**"""

#There are 33625 duplicates
df.index.duplicated().sum()

#Relabeling duplicates
df.index = df.index + ("_"+df.groupby(level=0).cumcount().astype(str)).replace('_0','')
df.head()

#Removed all duplicates
df.index.duplicated().sum()

#Example of relabelling post-duplicate-handling
#The second CDH1 instance has been relabelled to CDH1_1
df.loc[["CDH1","CDH1_1"],:]

"""**Handling Null Values**"""

df.isna()

"""We chose to keep nan values because if we turn nan values into 0, that will skew the distribution (since we want the nan value to be omitted from the analysis, not to beincluded as 0 since 0 has real meaning in this case).

# Gaussian Mixture Models
"""

#Isolating a row of the data to run the model on
temp = df.loc['CDH1',:].dropna()
temp

#Importing the existing GMM implementation from the sklearn.mixture package
from sklearn.mixture import GaussianMixture

#Reshaping the input array to make it two-dimensional
inp = np.array(temp).reshape(-1, 1)

#Functions to determine our model selection/goodness of fit metrics

#Writing a function to identify which indices in a sorted list a number lies between
#Parameters are "lis" (a sorted list from least to greatest) and "num" (a number of the user's choosing)
#The function returns the index of the maximum number in the list that is less than "num"
def find_ind(num, lis):
  i = 0
  while num > lis[i+1]:
    i += 1
  return i

#Writing a function to identify the area under a curve using the rectangular area approximation
#Parameters are "xl" and "yl" (the x and y values of the curve)
def rec_area_under(xl,yl):
  aund = 0
  for i in range(len(xl)-1):
    aund += (yl[i]*(xl[i+1]-xl[i]))
  return aund

#Writing a function to calculate our "Adjusted Least Squares" (ALS) metric
#Parameters are "bins" (the y-values of the bins in the histogram) and "preds" (the y-values (likelihoods) of the curve fitted to the distribution) 
ind_test = []
def ls_metric(preds, bins):
  ls_ls = 0
  for i in range(len(x)):
    ind = find_ind(x[i],bins)
    ind_test.append(ind)
    ls_ls += (abs(counts[ind]-preds[i])**2)
  return ls_ls

#Writing a function to calculate our "Area Under Difference" (AUD) metric
#Parameters are "hx" and "hy" (the x and y values of the bins in the histogram) and "px" and "py" (the x and y values of the curve fitted to the distribution)
def ar_metric(hx,hy,px,py):
  hund = rec_area_under(hx,hy)
  pund = rec_area_under(px,py)
  return pund-hund

#Fitting 1 component Gaussian Mixture Model

gmm1 = GaussianMixture(n_components = 1)
gmm1 = gmm1.fit(inp)
fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")  #the "weights" argument makes sure we graph the ratio rather than the count of frequencies on the y-axis
x= temp
y = np.exp(gmm1.score_samples(inp))
y = y*max(counts)/max(y)  #This line normalizes the y-values of the curve so we can compare the histogram and fitted curve on the same scale
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Gaussian Mixture Model BIC (1 Component) " + str(gmm1.bic(inp)))
print("Gaussian Mixture Model ALS (1 Component) " + str(ls_metric(y,bins)))
print("Gaussian Mixture Model AUD (1 Component) " + str(ar_metric(bins,counts,x,y)))
plt.show()

#Fitting 2 component Gaussian Mixture Model

gmm2 = GaussianMixture(n_components = 2)
gmm2 = gmm2.fit(inp)
fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")
x= temp
y = np.exp(gmm2.score_samples(inp))
y = y*max(counts)/max(y)
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Gaussian Mixture Model BIC (2 Components) " + str(gmm2.bic(inp)))
print("Gaussian Mixture Model ALS (2 Components) " + str(ls_metric(y,bins)))
print("Gaussian Mixture Model AUD (2 Components) " + str(ar_metric(bins,counts,x,y)))
plt.show()

"""# Student-t Mixture Models"""

#Installing the smm package for student-t mixture models
!pip install smm

#Importing the smm package and setting a random seed for reproducibility
import smm
seed = 123
np.random.seed(seed)

#Fitting 1 component Student-t Mixture Model

tmm1 = smm.SMM(n_components=1, covariance_type='full', random_state=seed, tol=1e-6, 
    min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')
tmm1.fit(inp)
fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black") 
x= temp
y = np.exp(tmm1.score_samples(inp)[0])
y=y*max(counts)/max(y)*(counts[0]/max(counts)) #This line normalizes the y-values of the curve so we can compare the histogram and fitted curve on the same scale
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Student-t Mixture Model BIC (1 Component) " + str(tmm1.bic(inp)))
print("Student-t Mixture Model ALS (1 Component) " + str(ls_metric(y,bins)))
print("Student-t Mixture Model AUD (1 Component) " + str(ar_metric(bins,counts,x,y)))
plt.show()

#Fitting 2 component Student-t Mixture Model

tmm2 = smm.SMM(n_components=2, covariance_type='full', random_state=seed, tol=1e-6, 
    min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')
tmm2.fit(inp)
fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")
x= temp
y = np.exp(tmm2.score_samples(inp)[0])
y=y*max(counts)/max(y)*(counts[0]/max(counts))
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Student-t Mixture Model BIC (2 Components) " + str(tmm2.bic(inp)))
print("Student-t Mixture Model ALS (2 Components) " + str(ls_metric(y,bins)))
print("Student-t Mixture Model AUD (2 Components) " + str(ar_metric(bins,counts,x,y)))
plt.show()

#Fitting 3 component Student-t Mixture Model

tmm3 = smm.SMM(n_components=3, covariance_type='full', random_state=seed, tol=1e-6, 
    min_covar=1e-6, n_iter=1000, n_init=1, params='wmcd', init_params='wmcd')
tmm3.fit(inp)
fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")
x= temp
y = np.exp(tmm3.score_samples(inp)[0])
y=y*max(counts)/max(y)*(counts[0]/max(counts))
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Student-t Mixture Model BIC (3 Components) " + str(tmm3.bic(inp)))
print("Student-t Mixture Model ALS (3 Components) " + str(ls_metric(y,bins)))
print("Student-t Mixture Model AUD (3 Components) " + str(ar_metric(bins,counts,x,y)))
plt.show()

"""# Weighted Average (of Gaussian and Student-t) Mixture Model"""

#Iterative process to determine weights

counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")
weight_acc = []
for i in range(1,10):
  #Varying weights from 0.1 to 0.9 with a 0.1 adjustment per iteration
  w1 = i *0.1
  w2 = 1-w1
  x= temp
  #Using the 3 component t and 2 component Gaussian mixture models for the average, as these had the best individual fits
  y = np.exp(np.average([tmm3.score_samples(inp)[0],gmm2.score_samples(inp)],axis=0,weights=[w1,w2]))*(max(counts)/max(y))
  #Calculating ALS and AUD for each variation of weights
  weight_acc.append([w1,w2,ls_metric(y,bins),abs(ar_metric(bins,counts,x,y)),(ls_metric(y,bins)+abs(ar_metric(bins,counts,x,y)))/2])
weight_acc.sort(key=lambda x: x[4]) #Sorting weights by mean(ALS, abs(AUD))
weight_acc

#Fitting weighted average mixture model

fig, ax = plt.subplots()
counts, bins, bars = ax.hist(temp,weights=np.ones(len(temp)) / len(temp),ec="black")
x= temp
#y = np.exp(np.mean([tmm.score_samples(inp)[0],gmm1.score_samples(inp)],axis=0))
w1 = 0.2
w2 = 0.8
y = np.exp(np.average([tmm3.score_samples(inp)[0],gmm2.score_samples(inp)],axis=0,weights=[w1,w2]))*(max(counts)/max(y))
x,y = zip(*sorted(zip(x,y),key=lambda x: x[0]))
ax.plot(x,y,"-k")
plt.title("CDH1")
plt.xlabel("log2 (expression value)")
plt.ylabel("Fraction of Samples")
print("Weighted Average Mixture Model BIC: " + str(w1*tmm3.bic(inp) + w2*gmm2.bic(inp)))
print("Weighted Average Mixture Model ALS: " + str(ls_metric(y,bins)))
print("Student-t Mixture Model AUD: " + str(ar_metric(bins,counts,x,y)))
plt.show()